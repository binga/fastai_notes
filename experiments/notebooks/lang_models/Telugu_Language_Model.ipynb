{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "\n",
    "from fastai.text import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = 'xbos'  # beginning-of-sentence tag\n",
    "FLD = 'xfld'  # data field tag\n",
    "\n",
    "PATH = pathlib.Path(\"lm/telugu/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM_PATH=Path('lm/telugu/telugu_lm/')\n",
    "LM_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['lm/telugu/data/AD/wiki_98',\n",
       " 'lm/telugu/data/AD/wiki_83',\n",
       " 'lm/telugu/data/AD/wiki_52',\n",
       " 'lm/telugu/data/AD/wiki_82',\n",
       " 'lm/telugu/data/AD/wiki_21']"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LANG_FILENAMES = [str(f) for f in PATH.rglob(\"*/*\")]\n",
    "print(len(LANG_FILENAMES))\n",
    "LANG_FILENAMES[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeError",
     "evalue": "UTF-16 stream does not start with BOM",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-278-e3ae50997d58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mLANG_TEXT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mLANG_FILENAMES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-16'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mLANG_TEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/anaconda3/envs/fastai/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/anaconda3/envs/fastai/lib/python3.6/encodings/utf_16.py\u001b[0m in \u001b[0;36m_buffer_decode\u001b[0;34m(self, input, errors, final)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutf_16_be_decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mconsumed\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mUnicodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"UTF-16 stream does not start with BOM\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeError\u001b[0m: UTF-16 stream does not start with BOM"
     ]
    }
   ],
   "source": [
    "LANG_TEXT = []\n",
    "for i in LANG_FILENAMES:\n",
    "    for line in open(i, encoding='utf-16'):\n",
    "        LANG_TEXT.append(json.loads(line))\n",
    "        \n",
    "LANG_TEXT = pd.DataFrame(LANG_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG_TEXT.to_csv(f\"{LM_PATH}/Wiki_Telugu_Corpus.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG_TEXT = pd.read_csv(f\"{LM_PATH}/Wiki_Telugu_Corpus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "(LANG_TEXT.assign(labels = 0)\n",
    "    .pipe(lambda x: x[['labels', 'text']])\n",
    "    .to_csv(f\"{LM_PATH}/Wiki_Telugu_Corpus2.csv\", header=None, index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some statistics of Telugu Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting rid of the title name in the text field\n",
    "def split_title_from_text(text):\n",
    "    words = text.split(\"\\n\\n\")\n",
    "    if len(words) >= 2:\n",
    "        return ''.join(words[1:])\n",
    "    else:\n",
    "        return ''.join(words)\n",
    "    \n",
    "LANG_TEXT['text'] = LANG_TEXT['text'].apply(lambda x: split_title_from_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69001, 4)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LANG_TEXT.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of words in all the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22174830"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LANG_TEXT['text'].apply(lambda x: len(x.split(\" \"))).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of unique tokens across documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2023536"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(''.join(LANG_TEXT['text'].values).split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts(df, n_lbls=1):\n",
    "    labels = df.iloc[:,range(n_lbls)].values.astype(np.int64)\n",
    "    texts = f'\\n{BOS} {FLD} 1 ' + df[n_lbls].astype(str)\n",
    "    for i in range(n_lbls+1, len(df.columns)): texts += f' {FLD} {i-n_lbls} ' + df[i].astype(str)\n",
    "    #texts = texts.apply(fixup).values.astype(str)\n",
    "\n",
    "    tok = Tokenizer().proc_all_mp(partition_by_cores(texts)) # splits the list into sublists for processing by each core\n",
    "    # Lower and upper case is inside the tokenizer\n",
    "    return tok, list(labels)\n",
    "\n",
    "def get_all(df, n_lbls):\n",
    "    tok, labels = [], []\n",
    "    for i, r in enumerate(df):\n",
    "        print(i)\n",
    "        #pdb.set_trace()\n",
    "        tok_, labels_ = get_texts(r, n_lbls)\n",
    "        tok += tok_;\n",
    "        labels += labels_\n",
    "    return tok, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG_TEXT = pd.read_csv(f\"{LM_PATH}/Wiki_Telugu_Corpus2.csv\", header=None)#, chunksize=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_texts,val_texts = sklearn.model_selection.train_test_split(\n",
    "    LANG_TEXT, test_size=0.1) # split the data into train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "trn_idx = np.random.permutation(len(trn_texts)) # generate a random ordering\n",
    "val_idx = np.random.permutation(len(val_texts))\n",
    "\n",
    "df_trn = trn_texts.iloc[trn_idx,:] # sort things randomly\n",
    "df_val = val_texts.iloc[val_idx,:] # sort things randomly\n",
    "\n",
    "df_trn.columns = ['labels', 'text']\n",
    "df_val.columns = ['labels', 'text']\n",
    "\n",
    "df_trn.to_csv(LM_PATH/'train.csv', header=False, index=False)\n",
    "df_val.to_csv(LM_PATH/'test.csv', header=False, index=False) # saving the data in our new format to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 10000\n",
    "df_trn = pd.read_csv(LM_PATH/'train.csv', header=None, chunksize=chunksize)\n",
    "df_val = pd.read_csv(LM_PATH/'test.csv', header=None, chunksize=chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn, trn_labels = get_all(df_trn, 1)\n",
    "tok_val, val_labels = get_all(df_val, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tmp directory to store the upcoming numpy arrays\n",
    "(LM_PATH/'tmp').mkdir(exist_ok=True)\n",
    "\n",
    "# save the train and validation tokens in the tmp directories\n",
    "np.save(LM_PATH/'tmp'/'tok_trn.npy', tok_trn)\n",
    "np.save(LM_PATH/'tmp'/'tok_val.npy', tok_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/src/anaconda3/envs/fastai/lib/python3.6/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'zmq.backend.cython.message.Frame.__dealloc__'\n",
      "Traceback (most recent call last):\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 12, in zmq.backend.cython.checkrc._check_rc\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-d6de5d336bfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtok_trn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLM_PATH\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'tmp'\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'tok_trn.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtok_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLM_PATH\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'tmp'\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'tok_val.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/src/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 421\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    422\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0mpickle_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tok_trn = np.load(LM_PATH/'tmp'/'tok_trn.npy')\n",
    "tok_val = np.load(LM_PATH/'tmp'/'tok_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the most common tokens and numericalizing the text\n",
    "freq = Counter(p for o in tok_trn for p in o) \n",
    "freq.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncating our vocab to ignore the rare words\n",
    "max_vocab = 60000\n",
    "min_freq = 5\n",
    "\n",
    "itos = [o for o,c in freq.most_common(max_vocab) if c>min_freq] # getting rid of the rare words\n",
    "itos.insert(0, '_pad_') # \n",
    "itos.insert(0, '_unk_') # itos is the list of all the strings in the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a index-key dictionary for our vocabulary\n",
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a index representation for our train and validation dataset\n",
    "trn_lm = np.array([[stoi[o] for o in p] for p in tok_trn])\n",
    "val_lm = np.array([[stoi[o] for o in p] for p in tok_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving our indexed representation of our dataset to disk\n",
    "# we also save the index-word mapping to retrieve the complete text representation from these numpy arrays\n",
    "np.save(LM_PATH/'tmp'/'trn_ids.npy', trn_lm)\n",
    "np.save(LM_PATH/'tmp'/'val_ids.npy', val_lm)\n",
    "pickle.dump(itos, open(LM_PATH/'tmp'/'itos.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the indexed representation of our dataset from disk\n",
    "# we also load the index-word mapping to to help us convert the indexes to word datasets, if need be.\n",
    "trn_lm = np.load(LM_PATH/'tmp'/'trn_ids.npy')\n",
    "val_lm = np.load(LM_PATH/'tmp'/'val_ids.npy')\n",
    "itos = pickle.load(open(LM_PATH/'tmp'/'itos.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60002, 62100)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking vocabulary size\n",
    "vs=len(itos)\n",
    "vs,len(trn_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! wget -nH -r -np http://files.fast.ai/models/wt103/\n",
    "# mv models/ {LM_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_sz,nh,nl = 400,1150,3\n",
    "\n",
    "PRE_PATH = LM_PATH/'models'/'wt103'\n",
    "PRE_LM_PATH = PRE_PATH/'fwd_wt103.h5'\n",
    "\n",
    "itos2 = pickle.load((PRE_PATH/'itos_wt103.pkl').open('rb')) # mapping the itos from wiki to our own mapping\n",
    "stoi2 = collections.defaultdict(lambda:-1, {v:k for k,v in enumerate(itos2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we train from scratch so these are unused\n",
    "wgts = torch.load(PRE_LM_PATH, map_location=lambda storage, loc: storage)\n",
    "\n",
    "enc_wgts = to_np(wgts['0.encoder.weight'])\n",
    "row_m = enc_wgts.mean(0)\n",
    "\n",
    "# wgts['0.encoder.weight'] = T(new_w)\n",
    "# wgts['0.encoder_with_dropout.embed.weight'] = T(np.copy(new_w))\n",
    "# wgts['1.decoder.weight'] = T(np.copy(new_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=1e-7\n",
    "bptt=70\n",
    "bs=52\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = LanguageModelLoader(np.concatenate(trn_lm), bs, bptt)\n",
    "val_dl = LanguageModelLoader(np.concatenate(val_lm), bs, bptt)\n",
    "md = LanguageModelData(PATH, 1, vs, trn_dl, val_dl, bs=bs, bptt=bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = np.array([0.25, 0.1, 0.2, 0.02, 0.15])*0.7 # if you're overfitting, increase this. Underfitting? decrease this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner= md.get_model(opt_fn, em_sz, nh, nl, \n",
    "    dropouti=drops[0], dropout=drops[1], wdrop=drops[2], dropoute=drops[3], dropouth=drops[4])\n",
    "\n",
    "learner.metrics = [accuracy]\n",
    "learner.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3\n",
    "lrs = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5276501e33543709f3a12b027960262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                      \n",
      "    0      3.417349   3.560564   0.536204  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.560563719257271, 0.536203954594169]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(lrs/2, 1, wds=wd, use_clr=(32,2), cycle_len=1) # last layer is the embedding weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('lm_telugu_fromscratch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load('lm_telugu_fromscratch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.lr_find(start_lr=lrs/10, end_lr=lrs*10, linear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67f36e4ac2e49ca974a29f00ecf4eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                     \n",
      "    0      3.14076    3.253949   0.551764  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.25394911041898, 0.5517637638358383]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(lrs, 1, wds=wd, use_clr=(20,10), cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('lm_telugu_fromscratch2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2663fe1e8d994bfe93ac9d11ad09832c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                     \n",
      "    0      3.064934   3.230878   0.550889  \n",
      "    1      2.937351   3.15471    0.551992                     \n",
      "    2      2.927289   3.08986    0.556666                     \n",
      "    3      2.867486   3.055522   0.559318                     \n",
      "    4      2.82416    3.033953   0.560748                     \n",
      "    5      2.810316   3.015779   0.562172                     \n",
      "    6      2.765557   2.998677   0.563972                     \n",
      "    7      2.745653   2.986154   0.565125                     \n",
      "    8      2.808281   2.972621   0.566626                     \n",
      "    9      2.733467   2.963909   0.566832                     \n",
      "    10     2.705382   2.952384   0.56811                      \n",
      "    11     2.718853   2.939511   0.569547                     \n",
      "    12     2.675635   2.938468   0.569217                     \n",
      "    13     2.671267   2.928721   0.570154                     \n",
      "    14     2.692976   2.91787    0.571475                     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.9178704515847462, 0.5714752661445426]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(lrs, 1, wds=wd, use_clr=(20,10), cycle_len=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('lm_telugu_fromscratch_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save_encoder('lm_telugu_fromscratch_enc_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLAS_PATH = Path(\"lm/telugu/telugu_clas/\")\n",
    "LM_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2615, 315)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clas_data = pd.read_csv(CLAS_PATH/\"ACTSA_telugu_polarity_annotated_UTF.txt\", sep=\"\\t\", header=None)\n",
    "df_clas_data[1] = df_clas_data[0].str[2:]\n",
    "df_clas_data[0] = df_clas_data[0].str[0:2]\n",
    "\n",
    "# Cleaning the target\n",
    "df_clas_data[0] = df_clas_data[0].str.strip()\n",
    "df_clas_data = df_clas_data[df_clas_data[0] != '+'].reset_index(drop=True)\n",
    "df_clas_data[0] = df_clas_data[0].astype(np.float32)\n",
    "\n",
    "df_clas_data.to_csv(CLAS_PATH/\"Telugu_Sentiment_Data.csv\", index=False)\n",
    "\n",
    "# Ignoring neutral class for this exercise\n",
    "df_clas_data = df_clas_data[df_clas_data[0] != 0].reset_index(drop=True)\n",
    "df_clas_data.loc[df_clas_data[0] == -1, 0] = 0\n",
    "\n",
    "# Creating train and validation sets\n",
    "np.random.seed(42)\n",
    "trn_keep = np.random.rand(len(df_clas_data))>0.1\n",
    "df_trn = df_clas_data[trn_keep]\n",
    "df_val = df_clas_data[~trn_keep]\n",
    "\n",
    "# Saving train and validation sets to disk\n",
    "df_trn.to_csv(CLAS_PATH/\"Telugu_Sentiment_Data_Train.csv\", header=None, index=False)\n",
    "df_val.to_csv(CLAS_PATH/\"Telugu_Sentiment_Data_Test.csv\", header=None, index=False)\n",
    "\n",
    "len(df_trn),len(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    1325\n",
       "0.0    1290\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trn[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 10000\n",
    "df_trn = pd.read_csv(CLAS_PATH/\"Telugu_Sentiment_Data_Train.csv\", header=None, chunksize=chunksize)\n",
    "df_val = pd.read_csv(CLAS_PATH/\"Telugu_Sentiment_Data_Test.csv\", header=None, chunksize=chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "tok_trn, trn_labels = get_all(df_trn, 1)\n",
    "tok_val, val_labels = get_all(df_val, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "(CLAS_PATH/'tmp').mkdir(exist_ok=True)\n",
    "\n",
    "np.save(CLAS_PATH/'tmp'/'tok_trn.npy', tok_trn)\n",
    "np.save(CLAS_PATH/'tmp'/'tok_val.npy', tok_val)\n",
    "\n",
    "np.save(CLAS_PATH/'tmp'/'trn_labels.npy', trn_labels)\n",
    "np.save(CLAS_PATH/'tmp'/'val_labels.npy', val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn = np.load(CLAS_PATH/'tmp'/'tok_trn.npy')\n",
    "tok_val = np.load(CLAS_PATH/'tmp'/'tok_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60002"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos = pickle.load((LM_PATH/'tmp'/'itos.pkl').open('rb'))\n",
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_clas = np.array([[stoi[o] for o in p] for p in tok_trn])\n",
    "val_clas = np.array([[stoi[o] for o in p] for p in tok_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(CLAS_PATH/'tmp'/'trn_ids.npy', trn_clas)\n",
    "np.save(CLAS_PATH/'tmp'/'val_ids.npy', val_clas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_clas = np.load(CLAS_PATH/'tmp'/'trn_ids.npy')\n",
    "val_clas = np.load(CLAS_PATH/'tmp'/'val_ids.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_labels = np.squeeze(np.load(CLAS_PATH/'tmp'/'trn_labels.npy'))\n",
    "val_labels = np.squeeze(np.load(CLAS_PATH/'tmp'/'val_labels.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt,em_sz,nh,nl = 70,400,1150,3\n",
    "vs = len(itos)\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
    "bs = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1290, 1: 1325})"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(trn_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lbl = trn_labels.min()\n",
    "trn_labels -= min_lbl\n",
    "val_labels -= min_lbl\n",
    "c=int(trn_labels.max())+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = TextDataset(trn_clas, trn_labels)\n",
    "val_ds = TextDataset(val_clas, val_labels)\n",
    "trn_samp = SortishSampler(trn_clas, key=lambda x: len(trn_clas[x]), bs=bs//2)\n",
    "val_samp = SortSampler(val_clas, key=lambda x: len(val_clas[x]))\n",
    "trn_dl = DataLoader(trn_ds, bs//2, transpose=True, num_workers=1, pad_idx=1, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, bs, transpose=True, num_workers=1, pad_idx=1, sampler=val_samp)\n",
    "md = ModelData(PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "dps = np.array([0.4, 0.5, 0.05, 0.3, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = get_rnn_classifer(bptt, 20*70, c, vs, emb_sz=em_sz, n_hid=nh, n_layers=nl, pad_token=1,\n",
    "          layers=[em_sz*3, 50, c], drops=[dps[4], 0.1],\n",
    "          dropouti=dps[0], wdrop=dps[1], dropoute=dps[2], dropouth=dps[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): MultiBatchRNN(\n",
       "    (encoder): Embedding(60002, 400, padding_idx=1)\n",
       "    (encoder_with_dropout): EmbeddingDropout(\n",
       "      (embed): Embedding(60002, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDrop(\n",
       "        (module): LSTM(400, 1150, dropout=0.3)\n",
       "      )\n",
       "      (1): WeightDrop(\n",
       "        (module): LSTM(1150, 1150, dropout=0.3)\n",
       "      )\n",
       "      (2): WeightDrop(\n",
       "        (module): LSTM(1150, 400, dropout=0.3)\n",
       "      )\n",
       "    )\n",
       "    (dropouti): LockedDropout(\n",
       "    )\n",
       "    (dropouths): ModuleList(\n",
       "      (0): LockedDropout(\n",
       "      )\n",
       "      (1): LockedDropout(\n",
       "      )\n",
       "      (2): LockedDropout(\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): ModuleList(\n",
       "      (0): LinearBlock(\n",
       "        (lin): Linear(in_features=1200, out_features=50, bias=True)\n",
       "        (drop): Dropout(p=0.1)\n",
       "        (bn): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (1): LinearBlock(\n",
       "        (lin): Linear(in_features=50, out_features=2, bias=True)\n",
       "        (drop): Dropout(p=0.1)\n",
       "        (bn): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner= md.get_model(opt_fn, em_sz, nh, nl, \n",
    "#     dropouti=drops[0], dropout=drops[1], wdrop=drops[2], dropoute=drops[3], dropouth=drops[4])\n",
    "\n",
    "# learner.metrics = [accuracy]\n",
    "# learner.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = RNN_Learner(md, TextModel(to_gpu(m)), opt_fn=opt_fn)\n",
    "learn.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learn.clip=25.\n",
    "learn.metrics = [accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=3e-3\n",
    "lrm = 2.6\n",
    "lrs = np.array([lr/(lrm**4), lr/(lrm**3), lr/(lrm**2), lr/lrm, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): RNN_Encoder(\n",
       "    (encoder): Embedding(60002, 400, padding_idx=1)\n",
       "    (encoder_with_dropout): EmbeddingDropout(\n",
       "      (embed): Embedding(60002, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDrop(\n",
       "        (module): LSTM(400, 1150, dropout=0.105)\n",
       "      )\n",
       "      (1): WeightDrop(\n",
       "        (module): LSTM(1150, 1150, dropout=0.105)\n",
       "      )\n",
       "      (2): WeightDrop(\n",
       "        (module): LSTM(1150, 400, dropout=0.105)\n",
       "      )\n",
       "    )\n",
       "    (dropouti): LockedDropout(\n",
       "    )\n",
       "    (dropouths): ModuleList(\n",
       "      (0): LockedDropout(\n",
       "      )\n",
       "      (1): LockedDropout(\n",
       "      )\n",
       "      (2): LockedDropout(\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=60002, bias=False)\n",
       "    (dropout): LockedDropout(\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs=np.array([1e-4,1e-4,1e-4,1e-3,1e-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = 1e-7\n",
    "wd = 0\n",
    "learn.load_encoder('lm_telugu_fromscratch_enc_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7232db5ceadf4152b9b5e0d903785d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 85/109 [00:01<00:00, 58.15it/s, loss=3.66] \n",
      "                                                           \r"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEOCAYAAAB4nTvgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xd8leXZwPHflQ2BhJEAIWEKKHsFcBRHXbxURVus4KSi2FppXzusttZSR21t+9rausC9pTiKiKJWqYKssCUMQ4AkkEAge49zvX+cEzyGk5yAeXLOCdf388mHZ9zPea48xly5n3uJqmKMMcY0JyzQARhjjAl+liyMMcb4ZcnCGGOMX5YsjDHG+GXJwhhjjF+WLIwxxvhlycIYY4xfliyMMcb45WiyEJEpIrJTRDJE5E4f5/uKyCcislFEtojIVM/xSBF5XkS2ish2EbnLyTiNMcY0z7FkISLhwKPA/wDDgJkiMqxRsbuBhao6FpgBPOY5fiUQraojgfHALSLS36lYjTHGNC/Cwc+eCGSoaiaAiLwGTAPSvcooEOfZjgcOeB2PFZEIoANQA5Q0d7OEhATt379/qwVvjDEng/Xr1x9W1UR/5ZxMFslAttd+DjCpUZl5wAciMheIBS7wHF+EO7HkAh2B21W1oLmb9e/fn7S0tFYI2xhjTh4isq8l5ZxssxAfxxrPWjgTeE5VU4CpwIsiEoa7VlIP9AYGAD8XkYHH3EBkjoikiUhafn5+60ZvjDHmKCeTRQ7Qx2s/ha9eMzWYDSwEUNVVQAyQAFwNvK+qtap6CFgJpDa+garOV9VUVU1NTPRbizLGGHOCnEwW64DBIjJARKJwN2AvblQmCzgfQESG4k4W+Z7j3xa3WOB0YIeDsRpjjGmGY8lCVeuA24BlwHbcvZ62ici9InKZp9jPgZtFZDPwKjBL3QtsPAp0Ar7AnXSeVdUtTsVqjDGmedJeFj9KTU1Va+A2xpjjIyLrVfWY1/yN2QhuY4wxflmyMMaYEJa2t4D1+5odWdAqLFkYY0wI+78Pd3Hfku2O38eShTHGhLDswgr6dOvo+H0sWRhjTIiqq3dxoKiKPl07OH4vSxbGGBOicourqHcpfa1mYYwxpinZhRUA9hrKGGNM03IKKgHo09WShTHGmCZkF1YQJpDUJcbxe1myMMaYEJVdUEFSfAciw53/VW7JwhhjQlR2YSV9ujnfEwosWRhjTMjKLqhok/YKsGRhjDEhqaq2nkOl1W3SEwosWRhjTEjKKfT0hLLXUMYYY5pydIxFe3gNJSJTRGSniGSIyJ0+zvcVkU9EZKOIbBGRqV7nRonIKhHZJiJbRcT5vmHGGBMicgrabkAeQIRTHywi4bhXvLsQ93rc60RksaqmexW7G/cKeo+LyDBgKdBfRCKAl4DrVHWziHQHap2K1RhjQk12YSVREWEkdopuk/s5WbOYCGSoaqaq1gCvAdMalVEgzrMdDxzwbF8EbFHVzQCqekRV6x2M1RhjQkp2QQUpXTsQFiZtcj8nk0UykO21n+M55m0ecK2I5OCuVcz1HB8CqIgsE5ENInKHg3EaY0zIyS5su26z4Gyy8JXuGi/4PRN4TlVTgKnAiyIShvv12LeAazz/XiEi5x9zA5E5IpImImn5+fmtG70xxgSxrCMVbdYTCpxNFjlAH6/9FL56zdRgNrAQQFVXATFAgufa/6rqYVWtwF3rGNf4Bqo6X1VTVTU1MTHRgW/BGGOCT3FlLSVVdW0yNXkDJ5PFOmCwiAwQkShgBrC4UZks4HwAERmKO1nkA8uAUSLS0dPYfQ6QjjHGGLIL2rbbLDjYG0pV60TkNty/+MOBZ1R1m4jcC6Sp6mLg58ACEbkd9yuqWaqqQKGI/B/uhKPAUlV916lYjTEmlOS04ToWDRxLFgCquhT3KyTvY/d4bacDZzVx7Uu4u88aY4zxkt2G61g0sBHcxhgTYrILK+gcE0F8x8g2u6clC2OMCTFtOdtsA0sWxhgTYtpyHYsGliyMMSaEqCo5bTwgDyxZGGNMSMkvq6aq1tWmPaHAkoUxxoSUoz2h7DWUMcaYpuS08ToWDSxZGGNMCGkYvZ1iycIYY0xTsgsqSegUTYeo8Da9ryULY4wJIdmFbTvbbANLFsYYE0JyCivb/BUUWLIwxpiQoarkFVfRu0tMm9/bkoUxxoSII+U11NS7SIqzZGGMMaYJecVVAPSKtzYLY4wxTcj1JAt7DWWMMaZJucXu0du94ttZshCRKSKyU0QyROROH+f7isgnIrJRRLaIyFQf58tE5BdOxmmMMaEgt7iKyHAhITa6ze/tWLIQkXDgUeB/gGHATBEZ1qjY3cBCVR2Le43uxxqdfxh4z6kYjTEmlOQWVdIzLoawMGnzeztZs5gIZKhqpqrWAK8B0xqVUSDOsx0PHGg4ISKXA5nANgdjNMaYkJFbXEXvADRug7PJIhnI9trP8RzzNg+4VkRycK/VPRdARGKBXwG/dzA+Y4wJKXklVQFprwBnk4WvepI22p8JPKeqKcBU4EURCcOdJB5W1bJmbyAyR0TSRCQtPz+/VYI2xphgpKrkFleRFKBkEeHgZ+cAfbz2U/B6zeQxG5gCoKqrRCQGSAAmAdNF5CGgC+ASkSpV/af3xao6H5gPkJqa2jgRGWNMu1FQXkNNnatdJot1wGARGQDsx92AfXWjMlnA+cBzIjIUiAHyVXVyQwERmQeUNU4UxhhzMskN4IA8cPA1lKrWAbcBy4DtuHs9bRORe0XkMk+xnwM3i8hm4FVglqpaDcEYYxoJ5IA8cLZmgaouxd1w7X3sHq/tdOAsP58xz5HgjDEmhARyQB7YCG5jjAkJgRyQB5YsjDEmJOQVVwVsQB5YsjDGmJBwoKgyYD2hwJKFMcaEhLySKpIC1BMKLFkYY0zQC/SAPLBkYYwxQS/QA/LAkoUxxgS9QA/IA0sWxhgT9BqShdUsjDHGNCnPMyAvKUCjt8GShTHGBL0DAR6QB5YsjDEm6AV6QB5YsjDGmKAX6AF5YMnCGGOCXqAH5IElC2OMCWrBMCAPLFkYY0xQaxiQF6ipyRs4mixEZIqI7BSRDBG508f5viLyiYhsFJEtIjLVc/xCEVkvIls9/37byTiNMSZYfTXGIrCvoRxb/EhEwoFHgQtxr8e9TkQWexY8anA37hX0HheRYbgXSuoPHAYuVdUDIjIC92p7yU7FaowxwSoYBuSBszWLiUCGqmaqag3wGjCtURkF4jzb8cABAFXdqKoHPMe3ATEiErgOxsYYEyDBMCAPnF1WNRnI9trPASY1KjMP+EBE5gKxwAU+Pud7wEZVrXYiSGOMCWbBMCAPnK1Z+Bo9oo32ZwLPqWoKMBV4UUSOxiQiw4E/Abf4vIHIHBFJE5G0/Pz8VgrbGGOCRzAMyANnk0UO0MdrPwXPayYvs4GFAKq6CogBEgBEJAV4C7heVXf7uoGqzlfVVFVNTUxMbOXwjTEm8HKLAz8gD5xNFuuAwSIyQESigBnA4kZlsoDzAURkKO5kkS8iXYB3gbtUdaWDMRpjTFDLLa4K6NTkDRxLFqpaB9yGuyfTdty9nraJyL0icpmn2M+Bm0VkM/AqMEtV1XPdIOC3IrLJ89XDqViNMSYYuVzuAXm9g6Bm4WQDN6q6FHd3WO9j93htpwNn+bjufuB+J2Mzxphgl19WTU2di5RuHQMdio3gNsaYYJVdUAFAStd2/BrKGGPMN5NT6B5j0aer1SyMMcY0wWoWxhhj/MoprCSxczQxkeGBDsWShTHGBKvswoqgqFWAJQtjjAlaOYWVQdFeAZYsjDEmKNW7lANFlVazMMYY07S8kirqXEqfIBhjAZYsjDEmKDX0hLLXUMYYY5oUTN1mwZKFMcYEpZzCSkSgdxdLFsYYY5qQXVhBr7gYoiKC49d0cERhjDHma4Kp2yxYsjDGmKCUUxA8A/LAkoUxxgSdmjoXeSVVQTE1eQNLFsYYE2RyiytxafD0hAKHk4WITBGRnSKSISJ3+jjfV0Q+EZGNIrJFRKZ6nbvLc91OEbnYyTiNMSaYBNPU5A0cWylPRMKBR4ELgRxgnYgs9qyO1+Bu3MutPi4iw3Cvqtffsz0DGA70Bj4SkSGqWu9UvMYYEyyCbYwFOFuzmAhkqGqmqtYArwHTGpVRIM6zHQ8c8GxPA15T1WpV3QNkeD7PGGPavezCCsLDhKQgWHu7gZPJIhnI9trP8RzzNg+4VkRycNcq5h7HtYjIHBFJE5G0/Pz81orbGGMCKqewkqT4GCLCg6dZ2clIxMcxbbQ/E3hOVVOAqcCLIhLWwmtR1fmqmqqqqYmJid84YGOMCQbZBRVB1V4BLUwWIvJTEYkTt6dFZIOIXOTnshygj9d+Cl+9ZmowG1gIoKqrgBggoYXXGmNMu5RTWEmfbsHTXgEtr1ncqKolwEVAIvAD4I9+rlkHDBaRASIShbvBenGjMlnA+QAiMhR3ssj3lJshItEiMgAYDKxtYazGGBOyqmrrOVRaTUqQ1Sxa2huq4bXQVOBZVd0sIr5eFR2lqnUichuwDAgHnlHVbSJyL5CmqouBnwMLROR23K+ZZqmqAttEZCGQDtQBP7aeUMaYk8H+Ik+32SCrWbQ0WawXkQ+AAcBdItIZcPm7SFWX4m649j52j9d2OnBWE9c+ADzQwviMMaZd+KrbbGjWLGYDY4BMVa0QkW64X0UZY4xpRcE4IA9a3mZxBrBTVYtE5Frcg+mKnQvLGGNOTtmFFUSFh9Gjc3SgQ/maliaLx4EKERkN3AHsA15wLCpjjDlJ5RRUkty1A2FhzTYLt7mWJos6T8PzNODvqvp3oLNzYRljzMkppzC4piZv0NJkUSoidwHXAe965n2KdC4sY4w5OWUXVgZd4za0PFlcBVTjHm+Rh3vqjT87FpUxxpyEyqrrKCivCd2ahSdBvAzEi8glQJWqWpuFMca0ol0HSwEY3KNTgCM5Vkun+/g+7hHUVwLfB9aIyHQnAzPGmJPNzjx3sjitV5yfkm2vpeMsfgNMUNVDACKSCHwELHIqMGOMOdnszCulY1R46L6GAsIaEoXHkeO41hhjTAtszy3h1F6dg67bLLS8ZvG+iCwDXvXsX0WjaTyMMcacOFVl58FS/mdEr0CH4lOLkoWq/lJEvod7HicB5qvqW45GZowxJ5FDpdUUVdRyas/gHMLW4jW4VfUN4A0HYzHGmJPW9twSAE5LCr7GbfCTLESkFB8r1OGuXaiqBud3ZYwxIearnlAhWLNQ1eCM2hhj2pmdeaX0jIumS8eoQIfik6M9mkRkiojsFJEMEbnTx/mHRWST52uXiBR5nXtIRLaJyHYRecTfYkvGGBPKduSVBuX4igYtbrM4Xp75ox4FLsS9pvY6EVnsWfAIAFW93av8XGCsZ/tM3I3pozynVwDnAMuditcYYwKltt5FxqEyJg9OCHQoTXKyZjERyFDVTFWtAV7DPWttU2byVddcxb0edxQQjXvSwoMOxmqMMQGz93A5NfUuTg3S9gpwNlkkA9le+zmeY8cQkX64l2z9GEBVVwGfALmer2Wqut3BWI0xJmB2BPE0Hw2cTBa+2hh89awCmAEsUtV6ABEZBAwFUnAnmG+LyNnH3EBkjoikiUhafn5+K4VtjDFta0deCeFhwik9YgMdSpOcTBY5QB+v/RTgQBNlZ/DVKyiAK4DVqlqmqmXAe8DpjS9S1fmqmqqqqYmJia0UtjHGtK2deaUMTIglOiI80KE0yclksQ4YLCIDRCQKd0JY3LiQiJwKdAVWeR3OAs4RkQgRicTduG2voYwx7dKOvNKgHYzXwLFkoap1wG3AMty/6Beq6jYRuVdELvMqOhN4zbNsa4NFwG5gK7AZ2Kyq7zgVqzHGBEppVS05hZVBOxivgWNdZwFUdSmNJhxU1Xsa7c/zcV09cIuTsRljTDBoWPAoWOeEamDTjBtjTAAd7QmVZMnCGGNME3bkltI5OoLkLsG34JE3SxbGGBNAO/NKGdKrM8E+o5ElC2OMCRBVZUdeSdA3boMlC2OMCZi8kipKquosWRhjjGlaxqEyAE7p0SnAkfhnycIYYwJkz+FyAE5JtGRhjDGmCZn55cRGhdOjc3SgQ/HLkoUxxgTInsPlDEiMDfqeUGDJwhhjAmbP4XIGJAT/KyiwZGGMMQFRXVdPTmEFAxKCd1pyb5YsjDEmALILKnApDLRkYYwxpim78909oaxmYYwxpkkN3WYHJFqyMMYY04Q9+eUkdIomLiYy0KG0iKPJQkSmiMhOEckQkTt9nH9YRDZ5vnaJSJHXub4i8oGIbBeRdBHp72SsxhjTlvYcLg+Z9gpwcPEjEQkHHgUuxL0e9zoRWayq6Q1lVPV2r/JzgbFeH/EC8ICqfiginQCXU7EaY0xbyzxczvmn9Qh0GC3mZM1iIpChqpmqWgO8BkxrpvxM4FUAERkGRKjqhwCqWqaqFQ7GaowxbaakqpbDZdUh014BziaLZCDbaz/Hc+wYItIPGAB87Dk0BCgSkTdFZKOI/NlTUzHGmJC319O4HUqvoZxMFr7Gr2sTZWcAizxrb4P79dhk4BfABGAgMOuYG4jMEZE0EUnLz8//5hEbY0wbyPR0mx1oNQvAXZPo47WfAhxoouwMPK+gvK7d6HmFVQe8DYxrfJGqzlfVVFVNTUxMbKWwjTHGWZmHywkT6NOtY6BDaTEnk8U6YLCIDBCRKNwJYXHjQiJyKtAVWNXo2q4i0pABvg2kN762Paipc/HvTfv5yasbyS6wZhljTgZ7DpeT0rUj0RGh83bdsd5QqlonIrcBy4Bw4BlV3SYi9wJpqtqQOGYCr6mqel1bLyK/AP4j7ukY1wMLnIo1EA6WVPHymixeWZPF4bJqADpEhvOn6aMCHJkxxml7DpeFzMjtBo4lCwBVXQosbXTsnkb785q49kOgXfzmLK2qZcmWXDIOlZGZX8bu/HKyC921iPNO7cF1Z/Tjo/SD/Csth59fPIQenWMCHLExximqyp78clL7dQt0KMfF0WRhYFN2EXNf3UB2QSXREWEMTOzEqJR4po9PYdqY3vTr7v7rYkD3WF5Zm8Xzn+/llxefFuCojTFOyS+tprymnlNCqHEbLFm0SFFFDdER4XSIavn7RZdLeXrFHv70/g56xsXw2pzTmdi/G2Fhvhc56Z8Qy8XDevHS6ixuPXcQsdH2n8aY9iizYU6oEFnHooHNDeVHbb2LS/6xgjkvpuHVrNKsw2XVzH5+HQ8s3c75Q3uw9CeTOX1g9yYTRYM55wykuLKWf6VlN1vOGBO6GrrNhtKAPLBk4dcH2w6SU1jJZ18eZtm2g82Wra138cyKPZz3l+WszDjCvdOG88S144nv2LKJwsb17Upqv648vXIPdfXNz25SW+/yW8YYE3z2HC4jOiKMpLjQapu0ZOHH85/vpU+3Dgzp2YkHlqZTVVvvs9znuw/znUc+494l6Yzp04WlP53M9Wf0P+61dW8+eyDZBZXNJqZ9R8o556FPuOvNrcf12caYwHMvpRrr901DsLFk0Yz0AyWs3VvA9af353eXDie7oJKnV+z5Wpl6l3L321u5esEaKmrqefK68bxw40QG9Tix95EXDO3JgIRY5n+62+drr+yCCmbOX82B4ir+vekARRU1J3QfY0xgZHqSRaixZNGM5z/fS4fIcL6f2oezBiVw8fCePPpJBnnFVQBU1dbz45c38NLqLOacPZCPfnYOFw/vddy1CW/hYcLsbw1gc04xT6/YQ2XNVzWZ/UWVzFywmrLqOh6aPoqaehfvbMn9xt+nMaZt1NW7yDpSEVLTfDSwZNGEwvIa3t60n8vHJh9tc/jN1GHUuZQ/vred0qpafvDsOt7flsc9lwzj11OHEhPZOqMxp49PYWzfLtz/7nZOf/A//GHpdtbvK+DqBasprqzlpZsmceX4FE7r1ZlF63Na5Z7GGOflFFZS59KQ6wkF1nW2Sa+nZVNd5+KGM/sdPda3e0dunjyARz/ZzZb9xWQdqeDhq0ZzxdiUVr13TGQ4b/7oTNbuKeCFVft4esUe5n+aSafoCF6cPZFRKV0Ad1K5/93tZBwqZVCPzq0agzGm9X15qAwIrQkEG1jNwod6l/Liqn2cPrAbp/WK+9q5W88dRM+4aA4UVbLg+tRWTxQNRIRJA7vz6DXjWPmrb3PHlFN5+aZJjO3b9WiZaWOSCQ8TFq3f70gMxpjWtSm7kIgwYVhSnP/CQcZqFj58tP0g+4squfs7Q485FxsdwcJbzqDepQxMbJuqZK/4GG49d9AxxxM7R3PukETe2pjDLy8+lfAQ611hzMlmw74ihvWOa7VX1m3JahaN7DpYymPLd9M7PoYLh/X0WaZf99g2SxT+TB+fwsGSalZkHA50KMaYZtS7lM05RYzt0yXQoZyQk75moarsOljGu1tzWbrVPdmfCDx4xUgiwoM/l357aA/iO0Tyxvoczhlia3oYE6x2HSyloqaecf26+i8chE76ZJFdUMnFf/sUEZjYvxvXTxvOlOG96BEioyujI8K5bHRvFqZlU1JVS6eoCD7ecYinVmRSXediwfWpJHSKDnSYxpz0NmQVAjC2jyWLkNS3e0f+dtUYzhzUPWSnBp8+PoUXV+/jt29/wdb9xWTml5MUH0NhRQ3XLFjDyzdPsoRhTIBtzCqie2wUfbp1CHQoJyT437O0gcvHJodsogAYlRLP4B6d+PemA3SMCufvM8bw6R3n8cwNE9hXUM41C9YcXWDpeBVX1PLmhhxufiGNUfOW8ft3tlHvatmEisaYr2zMKmRs3y7faNBuIDlasxCRKcDfca+U95Sq/rHR+YeB8zy7HYEeqtrF63wcsB14S1VvczLWUCYizL8+lSNl1Yzv1/XoD+OZgxJ45oYJ3Pj8Or81jB15JTz12R4qauqoq1dcqpRU1bFhXyF1LqVXXAxj+3bl2ZV7ySuu4uGrxoRkjw5jAqGooobd+eV8d5wzXe3bgmPJQkTCgUeBC4EcYJ2ILFbVo2tpq+rtXuXnAmMbfcx9wH+dirE9GZAQ63O+Ge+EceUTq7jj4lO5eHivo5OY1dW7mP9ZJg9/uIuYyHB6xcUQHiaEhwlREWHMnjyAKcN7MTqlC2FhwlOfZXL/u9s5Ur6WBdeltnhGXWNOZpuyiwAY2zc0e0KBszWLiUCGqmYCiMhrwDQgvYnyM4HfNeyIyHigJ/A+kOpgnO3emYMSeO4HE/n1m1v50csbGNSjEz8+7xRG9I7njje2sDGriKkje3H/5SPpFhvV7GfdNHkgiZ2j+cW/NnPlk5/z/I0TSYoPzXewxrSVjVlFhAmMTrFk4Usy4L2KTw4wyVdBEekHDAA+9uyHAX8FrgPOdzDGk8bpA7vz4c/O4d2tuTz6cQa3v74ZgPgOkfx9xhguG927xe9Sp41JJqFTNLe8uJ6bnk/jjR+daa+kjGnGhqxCTu0VF9IrYDoZua/fPE21jM4AFqlqwxSrtwJLVTW7uV9gIjIHmAPQt2/fbxDqySE8TLhsdG8uGZnER9sPsim7iBvO7E/PE+gmfNagBP4+Ywyzn0/j9+9s48HvjnIgYmNCn8ulbMou4tLRvQMdyjfiZLLIAfp47acAB5ooOwP4sdf+GcBkEbkV6AREiUiZqt7pfZGqzgfmA6SmploXnRYKCxMuGt6Li4b3+kafc/7Qntx67ik8tnw34/t1Y/r40G28M8YpmYfLKK2qC9mR2w2cTBbrgMEiMgDYjzshXN24kIicCnQFVjUcU9VrvM7PAlIbJwoTHH524RA2ZBVy99tbGd47jqEhOEGaMU7asK+hcTs0B+M1cGycharWAbcBy3B3f12oqttE5F4Rucyr6EzgNfW1LJwJehHhYTwycyxxMZHc+vIGSqpqAx2SMUFlY3Yh8R0iGRiCq+N5k/byOzo1NVXT0tICHcZJa03mEa5+ag09O0czeXAiZw7qzhkDu4fMtCnGOGXK3z6lZ1wMz984MdCh+CQi61XVb4/T0G2aN0Fl0sDuPHnteBamZfPeF7m8nubuCDd5cAL/mDmWLh2b75JrTHtUWlXLzoOlTBnxzdoHg4ElC9NqLhjWkwuG9aTepaQfKGH5zkP84+MMrnjsc56ZNSEkF6k35pvYklOMKowL8fYKsLmhjAPCw4SRKfHMPX8wr9w8ieLKWq54bCVr9xQEOjRj2tS6vQWIwOgQ7wkFliyMw1L7d+OtW8+kW2wU1zy1mrc3tv8lYNtLO6D55tZkFjAsKY74DqE/LY4lC+O4ft1jeetHZzG+X1duX7iJf29qfwmjpMo9O+9Nz69j+O+WcdebW6irdwU6LBNA1XX1bMgqZNKA7oEOpVVYm4VpE/EdI3nuBxOZ9exafrZwM7FREVzQxLK1oaK8uo6Pth9k8aYDfPplPrX1SlJ8DGcNSuDVtdkUltfy95ljiI6wqVBORpuzi6muczFpYLdAh9IqLFmYNhMTGc5TN0zgmgWrufWVDTz3gwmceUpCoMM6LqrK8p35vLlxPx+lH6Sytp6k+BhuOKM/U0clMcYzO+8zK/Zw75J0Zj+XxpPXjT86J9DOvFLe3ZqLqnLmKQmM69fFkkk7tSbzCCIwaUD7SBY2zsK0ucLyGmbMX01OYQUv3TTphEe2FpbXcOWTqxid0oW7vzOUrn5mzG0NT6/Yw31L0unaMZKpI5OYNiaZ1H5dj0757u2N9Tnc8cYWRibHc96pPViy5QBfHiojTNxrkNS7lJjIMCb078Z5p/bgu+OSrYtxO3LtU+5Fx97/37MDHUqzWjrOwpKFCYhDJVVc+eQqcouqmDSwG+cMSeTcU3twSmJsi2e//c1bW3l1bRZhInTpGMnvLh3OJaOSHFuJbENWId9/YhXnndaDx64ZR2S4/ya/ZdvymPvKRmpdLib068alo5OYMiKJ6Mgw1mYWsHL3YVZmHGbXwTKiIsL4zsgkZk7sy4T+XUN2RTUDNXUuRv1+GTMm9GXeZcMDHU6zLFmYoJdbXMlTn+1h+c5D7M4vB2BgQix/+O5ITh/YfKPgF/uLufSfK7jhjP5cNaEPv3pjC1tyirlgaA/+cMXIVh85XlRRw3ceWUFYGCy5bfJxLfp0sKQKVegV33RM6QdKeG1dFm9t2E9pdR0d0sgWAAAS9ElEQVQjkuN4ZMZYBiZ2+saxF1fU8vam/UwenNAqn2f8W7+vgO89voonrh3HlBFJgQ6nWZYsTEjJLqjgv7vyeXrFHvYdKecn5w9m7rcHE+7j9Y6qMv2JVew9XM7HvziX+A6R1NW7eO7zvfzlg52MSu7C67ec3mp/mbtcys0vpPHZl4dZ9KMzGOXgAjYVNXW8s/kAf3xvB3X1yp+vHH3Co3/ziqt4ekUmr6zJorymnh6do1n0wzPp271jK0dtGnv0kwz+vGwnG357od8FxQKtpcnCus6aoNCnW0euPb0f78z9FpePSeZvH33J1QtWk1tceUzZtzbuZ/2+Qn415bSj/dcjwsO4afJAfnfpcNbuLWDx5qZmwz9+8z/L5D87DnH3JUMdTRQAHaMiuGpCX5b8ZDIDe3Tihy+t58Gl24+rG+7ew+X8atEWJj/0Mc+s3MuFw3ryxLXjqal3ce3TazhUUuXgd2AAVmceYUjPTkGfKI6H1SxMUHpjfQ6//fcXREWEcfPkgVw9sS9dY6Morarl23/9L727dOCtH515TMNyvUu54rGV5BVX8fEvzqXTCaxMVlpVyxf7S9i6v4it+0tYujWXKcN78c+rx7ZpO0J1XT33LUnnpdVZnD6wG09e2/ya57vzy3j04wze3rSfyPAwZkzow02TB9Knm7smsSm7iKsXrKZP1468fsvp1pjukNp6F6N//wHfG5fCfZePCHQ4ftlrKBPyMvPLmPdOOp/uyicmMozvjkuhps7FovU5vP3jsxjTxBQKG7MKueKxz7nl7IHcNXVos/d4YdVeFqZlU1ZVR1l1PRU1dVTU1B89n9ylA5MGdOP304bTOSYwo3Df3JDDnW9sZUBCLC/MnnjMyob7iyr503s7eGfLAWIiwrnujH7cNHkAPTof20ayMuMwP3h2HcOT43jy2vHEdYgkOiLMGtNbUcPP36NXj+M7o4K7vQIsWZh2ZGdeKc+s2MNbm/ZTU+fiqtQ+/Gl688u43rFoM29u2M/7/3s2g3oc26hb71LufzedZ1fuZXSfLvTr1pHY6Ag6RYfTpWMUw3vHMTI5nu6dop36to7LyozDzHkhjW6donjxxkn0T4jF5VJeXL2Ph97fgUth1ln9uelbA/zG/P4Xedz68npcXv/rx0SGkRTfgRHJ8YzoHceI5HjG9OkS0mtGB8rjy3fzp/d3sO43F5DYOTh+fpoTFMlCRKYAfwfCgadU9Y+Nzj8MnOfZ7Qj0UNUuIjIGeByIA+qBB1T19ebuZcmi/TtcVs1H6QeZOiqJOD9/5R8uq+a8vyxndEoXXpw98Wt/OVfV1nP765t474s8bjxrAHd/Z6jPcRLBZnN2EbOeXUt4WBj3ThvOU59lsiGriMmDE/jDFSOPvm5qifX7CtiaU0xlrYvK2noqa+rIKqjgi/0l7C9ytxP1iovhpZsm+Uy2pmmznl1LdkEF//n5uYEOpUUCnixEJBzYBVyIez3udcBMVU1vovxcYKyq3igiQwBV1S9FpDewHhiqqkVN3c+ShWnsuZV7mPdOOj85fzDDkuKI6xBBbFQE97+bTtq+Qn4zdSg3TR4Y6DCPS8ahMq57eg25xVV06RjJPZcM44qxya36GqmgvIYN+wq5882tqCov3TTpa8vl1tW7eGrFHj7dlc+0Mb2ZNiaZmMivj0JPP1DC6swjXDyiF8ldOrRabMHE5VJ+uWgLa/Yc4UfnnsKV4/sQJjDm3g+ZNqY3D1wxMtAhtkgwJIszgHmqerFn/y4AVX2wifKfA79T1Q99nNsMTFfVL5u6nyUL01hdvYsrn1zFxqyv/40RFR7Gw1eNCYn3yb4cKKrkrY37uWpCHxIcfE22O7+MaxasoaqunhdunMiolC6kHyjhjjc288X+EnrFxZBXUkVCp2hmndmPqSOTWL4zn0Xrc0jPLQHcr7duPXcQc84eeExCCXV/en8Hjy/fTf/uHdl7pIKUrh24dHRvHl++m0dmjuWy0b0DHWKLBEOymA5MUdWbPPvXAZNU9TYfZfsBq4EUVa1vdG4i8DwwXFWb7D9oycL4UlfvIre4ipKqWooraymprGNQj1gG9egc6NBCQnZBBTMXrKa4opbLxybz6tosunSM4r5pw5kyohef7z7C/E8z+e+u/KPXjEqJ53vjUpjQvxuPfpLBu1tz6dOtA7/9zjAuGNozJF75+fPKmix+/dZWrp7UlwcuH8HyXfk8/OEutuQUA7D21+eHzJLCwZAsrgQubpQsJqrqXB9lf4U7UcxtdDwJWA7coKqrfVw3B5gD0Ldv3/H79u1r9e/DmJNdbnEl1yxYQ+bhcr47Lpl7Lhl2TLfbnXmlfPZlPmcPSWRIz68n4s8zDvO7xdv48lAZsVHhnJYUx2m9OjM0KY4pI3o5Wjv6php+P3q/5vtk5yFuej6NyYMTeOr6VCI8076oKv/ZfohDpdVcPalvQOI9EcGQLFr8GkpENgI/VtXPvY7F4U4UD6rqv/zdz2oWxjinuKKWrIIKRqbEn9D1tfUulmw5wMasInbklrI9t4TS6jo6x0Rwx8WncvWkfj5H6wdSdV09Vz6xiqyCCob2iuO0pM707daRvyzbSb/usSz84RknNI4n2ARDsojA3cB9PrAfdwP31aq6rVG5U4FlwAD1BCMiUcB7wDuq+reW3M+ShTGhQ1XZkVfK/e+mszLjCCOT47nv8hFNjp0JhIfe38Fjy3dzyagksgsr2ZlXQlWti6T4GN669axm5/oKJS1NFo6lRVWtE5HbcCeCcOAZVd0mIvcCaaq62FN0JvCafj1rfR84G+guIrM8x2ap6ian4jXGtB0RYWhSHC/NnsSSLbnctySdKx5byYje8XSNjaJbx0i6dIzi9IHduXh4zzYfNLgxq5An/rub76em8ND00YB7bM6+I+X0jIs5Kcef2KA8Y0zAlVbV8sR/d7PtQAmF5TUUVtRypKya8pp6Lhjag/suH0FSfNt0wa2qrWfqI59RVVPP+7ef7XdMT6gLeM3CGGNaqnNMJL+8+LSvHat3Kc+u3MNfPtjJRf/3KXdOPY2ZE/o22ZuquKKWpV/kUlRRS1l1LeXV7o6VN5414Lhm2v3zsp1k5pfz0uxJ7T5RHA+rWRhjgtq+I+Xc9eZWPt99hDMGdueRmWOPmUbjQFEl1z+zloxDZQCEhwmdoiOoqq1HBG6/YAizvzXgaM+lpqzdU8BV81dxzaS+3H95aAyq+6YC3sDd1ixZGNN+qSqvr8tm3jvbiO8QyePXjmecZznejENlXP/0Gkqq6njsmnFM6N+NmEj35Ii5xZXc8+9tfJh+kOG947j/8hFEhoeRnltC+oESduaVUlJVS2VtPVU19Rwpr6FnXAzv/XTySdMuYcnCGNPupB8o4ZaX0sgrruKeS4czKjneM1+W8NwPJjIi+diuvarK+1/kcc/ibeSXVh893jEqnCE9O5PQKYqYyHBiIsOJjQrnmtP7HTNWpD2zZGGMaZeKKmr439c3sXxnPhFhQlKXmKMz8TanuLKWtzbkkNg5hqFJnenXPTboxnYEgiULY0y75XIp//g4g7R9Bfz1ytEhM7VGMLLeUMaYdissTPjpBYMDHcZJxdbgNsYY45clC2OMMX5ZsjDGGOOXJQtjjDF+WbIwxhjjlyULY4wxflmyMMYY45clC2OMMX61mxHcIpIPtGQR7nig+BuWa+qcr+ONjzW3nwAcbkFsJ6Kl3/fxXuPUc/J1rC2e1Yk8p5ZeF4ifKQiuZ2X//7XuNf7KtORZ9VPVRL/RqOpJ9QXM/6blmjrn63jjY83t415BMKDf9/Fe49RzCtSzOpHnFOhn1YL9oHlW9v9f2/1MHe+z8vd1Mr6GeqcVyjV1ztfxxsf87TvlRO7Tkmucek6+jrXFszrRewTyWbW3nyl/5exZtbzM8TyrZrWb11DtgYikaQsm9DL2rI6HPauWsefUvJOxZhHM5gc6gBBiz6rl7Fm1jD2nZljNwhhjjF9WszDGGOOXJQtjjDF+WbIwxhjjlyWLECIisSKyXkQuCXQswUxEhorIEyKySER+FOh4gpmIXC4iC0Tk3yJyUaDjCVYiMlBEnhaRRYGOJVAsWbQBEXlGRA6JyBeNjk8RkZ0ikiEid7bgo34FLHQmyuDQGs9KVber6g+B7wPttitkKz2rt1X1ZmAWcJWD4QZMKz2nTFWd7Wykwc16Q7UBETkbKANeUNURnmPhwC7gQiAHWAfMBMKBBxt9xI3AKNzTEcQAh1V1SdtE37Za41mp6iERuQy4E/inqr7SVvG3pdZ6Vp7r/gq8rKob2ij8NtPKz2mRqk5vq9iDSUSgAzgZqOqnItK/0eGJQIaqZgKIyGvANFV9EDjmNZOInAfEAsOAShFZqqouRwMPgNZ4Vp7PWQwsFpF3gXaZLFrp50qAPwLvtcdEAa33M3Wys2QROMlAttd+DjCpqcKq+hsAEZmFu2bR7hJFM47rWYnIucB3gWhgqaORBZ/jelbAXOACIF5EBqnqE04GF0SO92eqO/AAMFZE7vIklZOKJYvAER/H/L4TVNXnWj+UoHdcz0pVlwPLnQomyB3vs3oEeMS5cILW8T6nI8APnQsn+FkDd+DkAH289lOAAwGKJdjZs2o5e1YtY8/pOFmyCJx1wGARGSAiUcAMYHGAYwpW9qxazp5Vy9hzOk6WLNqAiLwKrAJOFZEcEZmtqnXAbcAyYDuwUFW3BTLOYGDPquXsWbWMPafWYV1njTHG+GU1C2OMMX5ZsjDGGOOXJQtjjDF+WbIwxhjjlyULY4wxflmyMMYY45clCxMwIlLWBve4rIXTv7fmPc8VkTNP4LqxIvKUZ3uWiPyz9aM7fiLSv/H03j7KJIrI+20Vk2l7lixMyPNMN+2Tqi5W1T86cM/m5lU7FzjuZAH8GvjHCQUUYKqaD+SKyFmBjsU4w5KFCQoi8ksRWSciW0Tk917H3/asDrhNROZ4HS8TkXtFZA1whojsFZHfi8gGEdkqIqd5yh39C11EnhORR0TkcxHJFJHpnuNhIvKY5x5LRGRpw7lGMS4XkT+IyH+Bn4rIpSKyRkQ2ishHItLTMxX2D4HbRWSTiEz2/NX9huf7W+frF6qIdAZGqepmH+f6ich/PM/mPyLS13P8FBFZ7fnMe33V1MS9uuK7IrJZRL4Qkas8xyd4nsNmEVkrIp09NYjPPM9wg6/akYiEi8ifvf5b3eJ1+m3gGp//gU3oU1X7sq+AfAFlnn8vAubjngk0DFgCnO05183zbwfgC6C7Z1+B73t91l5grmf7VuApz/Ys3AsgATwH/Mtzj2G41zMAmI57KvMwoBdQCEz3Ee9y4DGv/a58NQvCTcBfPdvzgF94lXsF+JZnuy+w3cdnnwe84bXvHfc7wA2e7RuBtz3bS4CZnu0fNjzPRp/7PWCB1348EAVkAhM8x+Jwz0DdEYjxHBsMpHm2+wNfeLbnAHd7tqOBNGCAZz8Z2Bronyv7cubLpig3weAiz9dGz34n3L+sPgV+IiJXeI738Rw/AtQDbzT6nDc9/67HvZ6FL2+rey2QdBHp6Tn2LeBfnuN5IvJJM7G+7rWdArwuIkm4fwHvaeKaC4BhIkdnxY4Tkc6qWupVJgnIb+L6M7y+nxeBh7yOX+7ZfgX4i49rtwJ/EZE/AUtU9TMRGQnkquo6AFUtAXctBPiniIzB/XyH+Pi8i4BRXjWveNz/TfYAh4DeTXwPJsRZsjDBQIAHVfXJrx10L2J0AXCGqlaIyHLcy8oCVKlqfaPPqfb8W0/TP9vVXtvS6N+WKPfa/gfwf6q62BPrvCauCcP9PVQ287mVfPW9+dPiCd1UdZeIjAemAg+KyAe4Xxf5+ozbgYPAaE/MVT7KCO4a3DIf52Jwfx+mHbI2CxMMlgE3ikgnABFJFpEeuP9qLfQkitOA0x26/wrge562i564G6hbIh7Y79m+wet4KdDZa/8D3DOcAuD5y72x7cCgJu7zOe4ptMHdJrDCs70a92smvM5/jYj0BipU9SXcNY9xwA6gt4hM8JTp7Gmwj8dd43AB1+Fej7qxZcCPRCTSc+0QT40E3DWRZntNmdBlycIEnKp+gPs1yioR2Qoswv3L9n0gQkS2APfh/uXohDdwL4bzBfAksAYobsF184B/ichnwGGv4+8AVzQ0cAM/AVI9DcLp+FhxTVV34F7atHPjc57rf+B5DtcBP/Uc/1/gZyKyFvdrLF8xjwTWisgm4DfA/apaA1wF/ENENgMf4q4VPAbcICKrcf/iL/fxeU8B6cAGT3faJ/mqFnce8K6Pa0w7YFOUGwOISCdVLRP3WstrgbNUNa+NY7gdKFXVp1pYviNQqaoqIjNwN3ZPczTI5uP5FJimqoWBisE4x9osjHFbIiJdcDdU39fWicLjceDK4yg/HneDtABFuHtKBYSIJOJuv7FE0U5ZzcIYY4xf1mZhjDHGL0sWxhhj/LJkYYwxxi9LFsYYY/yyZGGMMcYvSxbGGGP8+n+Ray+N+xqvtQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(lrs/1000)\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = 5e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60151ff536994700a2eaf5c54c6b5eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.681524   0.650897   0.606812  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6508973751749311, 0.606812162058694]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('clas_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('clas_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ab3c9de5ce498284f2260e37087a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.673592   0.674057   0.572751  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6740570919854301, 0.5727513219629016]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs=np.array([1e-4,1e-4,1e-4,1e-3,1e-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e22de4e936b4d1aac8e9703753cf907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=14), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.603622   2.29852    0.576389  \n",
      "    1      0.608366   7.834564   0.573413                    \n",
      "    2      0.606213   0.70147    0.595238                    \n",
      "    3      0.600061   0.710632   0.582341                    \n",
      "    4      0.611266   0.644456   0.595238                    \n",
      "    5      0.610971   0.651843   0.586971                    \n",
      "    6      0.611401   0.649413   0.590608                    \n",
      "    7      0.603971   0.645054   0.605489                    \n",
      "    8      0.611684   0.826125   0.587632                    \n",
      "    9      0.603468   2.090982   0.607804                    \n",
      "    10     0.603244   1.25904    0.611442                    \n",
      "    11     0.620156   0.640724   0.619048                    \n",
      "    12     0.60379    1.975962   0.604828                    \n",
      "    13     0.603165   0.64839    0.605489                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6483896459851947, 0.605489411524364]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=14, use_clr=(32,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "mywork/Telugu_Language_Model.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
